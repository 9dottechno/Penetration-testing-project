# --- Extensibility & Custom Rules ---
import importlib
custom_rules = []
def load_custom_rules(rule_modules):
    global custom_rules
    for mod_name in rule_modules:
        try:
            mod = importlib.import_module(mod_name)
            if hasattr(mod, 'register_rules'):
                custom_rules.extend(mod.register_rules())
                print(f"[CustomRules] Loaded from {mod_name}")
        except Exception as e:
            print(f"[CustomRules Error] {e}")

def apply_custom_rules(findings):
    for rule in custom_rules:
        findings = rule(findings)
    return findings

def add_custom_ai_prompt(prompt):
    # Store or use custom AI prompts for business logic testing
    print(f"[CustomAI] Added prompt: {prompt}")
# --- Notifications & Alerting ---
import smtplib
def send_email_notification(subject, body, to_emails):
    # Simple SMTP email notification (stub, configure for real use)
    print(f"[Email] To: {to_emails} | Subject: {subject}\n{body}")
    # Uncomment and configure for real SMTP
    # with smtplib.SMTP('smtp.example.com') as server:
    #     server.login('user', 'pass')
    #     message = f"Subject: {subject}\n\n{body}"
    #     server.sendmail('from@example.com', to_emails, message)

def send_teams_notification(message, webhook_url):
    import requests
    try:
        resp = requests.post(webhook_url, json={"text": message})
        print(f"[Teams] {resp.status_code} {resp.text}")
    except Exception as e:
        print(f"[Teams Error] {e}")
# --- Compliance & Audit Logging ---
import json as _json
def audit_log(action, details=None):
    entry = {
        "timestamp": datetime.now().isoformat(),
        "action": action,
        "details": details or {}
    }
    with open("audit_log.json", "a") as f:
        f.write(_json.dumps(entry) + "\n")
    logging.info(f"[AUDIT] {action} - {details}")
# --- Secrets & Sensitive Data Handling ---
import base64
# --- Secrets Handling Utility ---
def get_secret(key, default=None):
    # Load from env, .env, or vaults (HashiCorp, AWS, Azure)
    val = os.getenv(key, default)
    if val and val.startswith('base64:'):
        return base64.b64decode(val[7:]).decode()
    # Try Vault
    vault_val = get_vault_secret(key)
    if vault_val:
        return vault_val
    # Try AWS Secrets Manager
    try:
        import boto3
        client = boto3.client('secretsmanager')
        aws_val = client.get_secret_value(SecretId=key).get('SecretString')
        if aws_val:
            return aws_val
    except Exception:
        pass
    # Try Azure Key Vault
    try:
        from azure.identity import DefaultAzureCredential
        from azure.keyvault.secrets import SecretClient
        kv_url = os.getenv('AZURE_KEYVAULT_URL')
        if kv_url:
            credential = DefaultAzureCredential()
            client = SecretClient(vault_url=kv_url, credential=credential)
            az_val = client.get_secret(key).value
            if az_val:
                return az_val
    except Exception:
        pass
    return val

# Vault integration stub (for HashiCorp Vault, AWS Secrets Manager, etc.)
def get_vault_secret(key):
    # HashiCorp Vault integration
    try:
        import hvac
        vault_url = os.getenv('VAULT_ADDR')
        vault_token = os.getenv('VAULT_TOKEN')
        if vault_url and vault_token:
            client = hvac.Client(url=vault_url, token=vault_token)
            secret = client.secrets.kv.read_secret_version(path=key)
            return secret['data']['data'].get(key)
    except Exception:
        pass
    print(f"[Vault] Fetching secret for {key} (stub)")
    return None

def mask_sensitive(text, secrets=None):
    if not secrets:
        secrets = [get_secret("OPENAI_API_KEY"), get_secret("ZAP_USER"), get_secret("ZAP_PASS")]
        # Add secrets from vault, AWS, Azure if available
        for key in ["OPENAI_API_KEY", "ZAP_USER", "ZAP_PASS"]:
            vault_secret = get_vault_secret(key)
            if vault_secret:
                secrets.append(vault_secret)
            try:
                import boto3
                client = boto3.client('secretsmanager')
                aws_secret = client.get_secret_value(SecretId=key).get('SecretString')
                if aws_secret:
                    secrets.append(aws_secret)
            except Exception:
                pass
            try:
                from azure.identity import DefaultAzureCredential
                from azure.keyvault.secrets import SecretClient
                kv_url = os.getenv('AZURE_KEYVAULT_URL')
                if kv_url:
                    credential = DefaultAzureCredential()
                    client = SecretClient(vault_url=kv_url, credential=credential)
                    az_secret = client.get_secret(key).value
                    if az_secret:
                        secrets.append(az_secret)
            except Exception:
                pass
    masked = text
    for secret in secrets:
        if secret and secret in masked:
            masked = masked.replace(secret, "[REDACTED]")
    return masked

# --- Scalability & Parallelism ---
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue
import threading

def distributed_scan_worker(scan_queue, result_queue):
    while True:
        try:
            item = scan_queue.get(timeout=5)
        except queue.Empty:
            break
        scanner_name, args = item
        try:
            output = run_scanner(scanner_name)
            findings = parse_scanner_output(scanner_name, output)
            result_queue.put((scanner_name, findings))
        except Exception as e:
            logging.error(f"[DistributedScan] Error in {scanner_name}: {e}")
            result_queue.put((scanner_name, []))
        finally:
            scan_queue.task_done()

def run_distributed_scans(scanner_list, max_workers=4):
    scan_queue = queue.Queue()
    result_queue = queue.Queue()
    for scanner_name in scanner_list:
        scan_queue.put((scanner_name, {}))
    threads = []
    for _ in range(max_workers):
        t = threading.Thread(target=distributed_scan_worker, args=(scan_queue, result_queue))
        t.start()
        threads.append(t)
    scan_queue.join()
    for t in threads:
        t.join()
    results = {}
    while not result_queue.empty():
        scanner_name, findings = result_queue.get()
        results[scanner_name] = findings
    return results
# --- Workflow Orchestration & Error Handling ---
import logging
import traceback
logging.basicConfig(filename='pentest_framework.log', level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

def safe_run(func, *args, **kwargs):
    try:
        return func(*args, **kwargs)
    except Exception as e:
        logging.error(f"Error in {func.__name__}: {e}\n{traceback.format_exc()}")
        print(f"[Error] {func.__name__} failed: {e}")
        return None
# --- False Positive Filtering & Deduplication ---
def deduplicate_findings(findings):
    seen = set()
    deduped = []
    for f in findings:
        key = (f.name, f.severity, tuple(f.affected_endpoints), f.cwe)
        if key not in seen:
            deduped.append(f)
            seen.add(key)
    return deduped

def filter_false_positives(findings, rules=None):
    # Example: filter by known false positive patterns or user rules
    filtered = []
    for f in findings:
        if rules:
            skip = False
            for rule in rules:
                if rule in f.description or rule in f.name:
                    skip = True
                    break
            if skip:
                continue
        filtered.append(f)
    return filtered
# --- API Discovery & Fuzzing ---
import glob
import yaml
class APIDiscoveryFuzzer:
    def __init__(self, base_path="."):
        self.base_path = base_path
        self.api_endpoints = []

    def discover_from_openapi(self):
        # Find OpenAPI/Swagger files
        files = glob.glob(f"{self.base_path}/**/*.yaml", recursive=True) + glob.glob(f"{self.base_path}/**/*.json", recursive=True)
        for file in files:
            try:
                with open(file, "r") as f:
                    if file.endswith(".yaml") or file.endswith(".yml"):
                        spec = yaml.safe_load(f)
                    else:
                        spec = json.load(f)
                paths = spec.get("paths", {})
                for path, methods in paths.items():
                    for method in methods:
                        self.api_endpoints.append((method.upper(), path))
            except Exception as e:
                print(f"[APIDiscovery] Error parsing {file}: {e}")
        return self.api_endpoints

    def fuzz_endpoints(self, base_url, method="GET", payloads=None):
        try:
            from boofuzz import Session, Target, Request
        except ImportError:
            logging.error("[Fuzzing] boofuzz not installed.")
            return []
        results = []
        for verb, endpoint in self.api_endpoints:
            if method and verb != method:
                continue
            logging.info(f"[Fuzzing] Fuzzing {verb} {base_url}{endpoint}")
            session = Session(target=Target(connection=None))
            # Example: fuzz GET endpoints with simple payloads
            req = Request(endpoint)
            if payloads:
                for payload in payloads:
                    req.add_payload(payload)
            session.add_request(req)
            try:
                session.fuzz()
                # Collect results (stub: boofuzz output parsing not implemented)
                results.append({"endpoint": endpoint, "method": verb, "status": "fuzzed"})
            except Exception as e:
                logging.error(f"[Fuzzing] Error fuzzing {endpoint}: {e}")
                results.append({"endpoint": endpoint, "method": verb, "status": "error", "error": str(e)})
        return results
# --- Dynamic User/Role Mapping & Privilege Escalation/IDOR Testing ---
from bs4 import BeautifulSoup
class UserRoleMapper:
    def __init__(self, base_url, roles=None):
        self.base_url = base_url
        self.roles = roles or {}
        self.sessions = {}
        if not self.roles:
            self.roles = self.discover_roles()
        for role, creds in self.roles.items():
            session = AuthSession(base_url, **creds)
            if session.login():
                self.sessions[role] = session
            else:
                logging.warning(f"[UserRoleMapper] Login failed for role: {role}")

    def discover_roles(self):
        # Automated role discovery stub
        # In real implementation, crawl registration/login pages, enumerate roles from app metadata or API
        print("[UserRoleMapper] Automated role discovery not yet implemented.")
        # Example: return hardcoded roles for now
        return {"admin": {"username": "admin", "password": "adminpass"}, "user": {"username": "user", "password": "userpass"}}

    def crawl_endpoints(self, start_path="/"):
        # Crawl as each role, collect endpoints and permissions
        endpoints = set()
        permissions = {}
        for role, session in self.sessions.items():
            try:
                resp = session.get(start_path)
                if resp.status_code == 200:
                    soup = BeautifulSoup(resp.text, "html.parser")
                    for link in soup.find_all("a", href=True):
                        endpoints.add(link['href'])
                        permissions.setdefault(link['href'], []).append(role)
            except Exception as e:
                logging.error(f"[UserRoleMapper] Error crawling as {role}: {e}")
        return list(endpoints), permissions

    def test_privilege_escalation(self, endpoint):
        # Try to access endpoint as each role, compare responses
        results = {}
        for role, session in self.sessions.items():
            try:
                resp = session.get(endpoint)
                results[role] = resp.status_code
            except Exception as e:
                logging.error(f"[UserRoleMapper] Error testing privilege escalation for {role}: {e}")
                results[role] = None
        return results

    def test_idor(self, endpoint, param_name, test_values):
        # Try to access resource IDs as different users
        idor_results = {}
        for role, session in self.sessions.items():
            for val in test_values:
                try:
                    url = f"{endpoint}?{param_name}={val}"
                    resp = session.get(url)
                    idor_results[(role, val)] = resp.status_code
                except Exception as e:
                    logging.error(f"[UserRoleMapper] Error testing IDOR for {role}, value {val}: {e}")
                    idor_results[(role, val)] = None
        return idor_results
import requests
from urllib.parse import urljoin

# --- Authentication/Session Handling ---
class AuthSession:
    def __init__(self, base_url, username=None, password=None, login_path="/login", login_payload=None, token_field=None, cookie_name=None, oauth_config=None, saml_config=None, mfa_config=None):
        self.base_url = base_url
        self.session = requests.Session()
        self.token = None
        self.cookie = None
        self.username = username
        self.password = password
        self.login_path = login_path
        self.login_payload = login_payload
        self.token_field = token_field
        self.cookie_name = cookie_name
        self.oauth_config = oauth_config
        self.saml_config = saml_config
        self.mfa_config = mfa_config

    def login(self):
        # Basic login
        url = urljoin(self.base_url, self.login_path)
        payload = self.login_payload or {"username": self.username, "password": self.password}
        try:
            resp = self.session.post(url, data=payload)
            if self.token_field and self.token_field in resp.json():
                self.token = resp.json()[self.token_field]
            if self.cookie_name and self.cookie_name in resp.cookies:
                self.cookie = resp.cookies[self.cookie_name]
            # OAuth2 stub
            if self.oauth_config:
                print("[AuthSession] OAuth2 flow not yet implemented.")
                # Implement OAuth2 token retrieval here
            # SAML stub
            if self.saml_config:
                print("[AuthSession] SAML flow not yet implemented.")
                # Implement SAML assertion retrieval here
            # MFA stub
            if self.mfa_config:
                print("[AuthSession] MFA flow not yet implemented.")
                # Implement multi-factor authentication here
            return resp.status_code == 200
        except Exception as e:
            logging.error(f"[AuthSession Error] Login failed: {e}")
            return False

    def get_headers(self):
        headers = {}
        if self.token:
            headers["Authorization"] = f"Bearer {self.token}"
        # Add OAuth2 token if available
        if self.oauth_config and hasattr(self, 'oauth_token'):
            headers["Authorization"] = f"Bearer {self.oauth_token}"
        # Add SAML assertion if available
        if self.saml_config and hasattr(self, 'saml_assertion'):
            headers["SAMLAssertion"] = self.saml_assertion
        return headers

    def get_cookies(self):
        if self.cookie:
            return {self.cookie_name: self.cookie}
        return {}

    def get(self, path):
        url = urljoin(self.base_url, path)
        return self.session.get(url, headers=self.get_headers(), cookies=self.get_cookies())

    def post(self, path, data=None):
        url = urljoin(self.base_url, path)
        return self.session.post(url, data=data, headers=self.get_headers(), cookies=self.get_cookies())

import subprocess
import json
import uuid
from datetime import datetime

# --- Config ---

SCANNERS = {
    "zap": ["zap-cli", "quick-scan", "http://localhost:3000"],
    "nmap": ["nmap", "-sV", "localhost"],
    "semgrep": ["semgrep", "--config", "auto", "./"],
    "snyk": ["snyk", "test"],
    "boofuzz": ["python", "boofuzz_script.py"],
    "sslyze": ["sslyze", "--regular", "localhost"],
    "lynis": ["lynis", "audit", "system"],
    "wsl_lynis": ["lynis", "audit", "system"],
    "wsl_nikto": ["nikto", "-h", "localhost"],
    # Add more WSL-based tools as needed
}

# --- Core Classes ---
class Finding:
    def __init__(self, name, severity, description, evidence, remediation, owasp, sans, cwe, endpoints, poc, consequence, likelihood, impact):
        self.id = str(uuid.uuid4())
        self.name = name
        self.severity = severity
        self.description = description
        self.evidence = evidence
        self.remediation = remediation
        self.owasp = owasp
        self.sans = sans
        self.cwe = cwe
        self.affected_endpoints = endpoints
        self.poc = poc
        self.consequence = consequence
        self.likelihood = likelihood
        self.impact = impact

    def to_dict(self):
        return self.__dict__

class Report:
    def __init__(self):
        self.findings = []
        self.generated_at = datetime.now().isoformat()
        self.certificate = None

    def add_finding(self, finding):
        # Mask sensitive data in finding before storing
        finding.name = mask_sensitive(finding.name)
        finding.description = mask_sensitive(finding.description)
        finding.evidence = mask_sensitive(finding.evidence)
        finding.remediation = mask_sensitive(finding.remediation)
        finding.owasp = mask_sensitive(finding.owasp)
        finding.sans = mask_sensitive(finding.sans)
        finding.cwe = mask_sensitive(finding.cwe)
        finding.poc = mask_sensitive(finding.poc)
        finding.consequence = mask_sensitive(finding.consequence)
        self.findings.append(finding)

    def to_json(self):
        # Mask sensitive data in output
        findings_dict = [mask_sensitive(json.dumps(f.to_dict())) for f in self.findings]
        return json.dumps({
            "generated_at": self.generated_at,
            "findings": findings_dict,
            "certificate": mask_sensitive(json.dumps(self.certificate)) if self.certificate else None
        }, indent=2)

def run_wsl_scanner(command):
    print(f"Running WSL scanner: {' '.join(command)}")
    try:
        result = subprocess.run(['wsl'] + command, capture_output=True, text=True, timeout=300)
        return result.stdout
    except Exception as e:
        print(f"Error running WSL scanner: {e}")
        return ""

def run_scanner(name):
    logging.info(f"[Scanner] Running: {name}")
    cmd = SCANNERS.get(name)
    if not cmd:
        logging.error(f"Scanner {name} not configured.")
        return ""
    try:
        if name == "zap":
            zap_api = get_secret("ZAP_API", "http://localhost:8080")
            target = "http://localhost:3000"
            import requests
            scan_url = f"{zap_api}/JSON/ascan/action/scan/?url={target}&recurse=true"
            scan_resp = requests.get(scan_url)
            scan_id = scan_resp.json().get('scan')
            status_url = f"{zap_api}/JSON/ascan/view/status/?scanId={scan_id}"
            while True:
                status = requests.get(status_url).json().get('status')
                if status == '100':
                    break
                import time; time.sleep(2)
            alerts_url = f"{zap_api}/JSON/core/view/alerts/?baseurl={target}"
            alerts_resp = requests.get(alerts_url)
            logging.info(f"[ZAP] Scan complete for {target}")
            return json.dumps({"site": [{"alerts": alerts_resp.json().get('alerts', [])}]})
        if name.startswith("wsl_"):
            return run_wsl_scanner(cmd)
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        logging.info(f"[Scanner] {name} output: {result.stdout[:500]}")
        return result.stdout
    except Exception as e:
        logging.error(f"[Scanner Error] {name}: {e}")
        return ""

# --- Real Scanner Output Parsing ---
import lxml.etree as ET

def capture_screenshot(url, filename):
    # Stub: Implement screenshot capture logic here (e.g., Selenium, requests-html, etc.)
    # For now, just log and create an empty file as a placeholder
    logging.info(f"[Screenshot] Capturing screenshot for {url} -> {filename}")
    with open(filename, "wb") as f:
        pass

def parse_zap_json(output):
    try:
        data = json.loads(output)
        findings = []
        for site in data.get('site', []):
            for alert in site.get('alerts', []):
                endpoint_urls = [a.get('url', '') for a in alert.get('instances', [])]
                screenshot_file = None
                http_log = None
                if endpoint_urls:
                    try:
                        screenshot_file = f"evidence_{uuid.uuid4().hex}.png"
                        capture_screenshot(endpoint_urls[0], screenshot_file)
                        http_log = f"HTTP log for {endpoint_urls[0]}" # Stub: real HTTP log capture needed
                    except Exception as e:
                        logging.error(f"[Evidence] Error capturing for {endpoint_urls[0]}: {e}")
                findings.append(Finding(
                    name=alert.get('alert', 'ZAP Finding'),
                    severity=alert.get('risk', 'Medium'),
                    description=alert.get('desc', ''),
                    evidence=alert.get('evidence', ''),
                    remediation=alert.get('solution', ''),
                    owasp=alert.get('reference', ''),
                    sans='',
                    cwe=alert.get('cweid', ''),
                    endpoints=endpoint_urls,
                    poc=screenshot_file or '',
                    consequence=http_log or '',
                    likelihood='',
                    impact=alert.get('risk', '')
                ))
        return findings
    except Exception as e:
        print(f"[ZAP Parse Error] {e}")
        return []

def parse_nmap_xml(output):
    try:
        root = ET.fromstring(output)
        findings = []
        for host in root.findall('.//host'):
            for port in host.findall('.//port'):
                state = port.find('state').get('state')
                if state != 'open':
                    continue
                service = port.find('service')
                endpoint = f"{host.find('address').get('addr')}:{port.get('portid')}"
                screenshot_file = None
                http_log = None
                try:
                    screenshot_file = f"evidence_{uuid.uuid4().hex}.png"
                    capture_screenshot(f"http://{endpoint}", screenshot_file)
                    http_log = f"Nmap log for {endpoint}" # Stub: real HTTP log capture needed
                except Exception as e:
                    logging.error(f"[Evidence] Error capturing for {endpoint}: {e}")
                findings.append(Finding(
                    name=f"Open Port {port.get('portid')}",
                    severity="Info",
                    description=f"Service: {service.get('name')}",
                    evidence=ET.tostring(port).decode(),
                    remediation="Close unused ports.",
                    owasp="A06:2021",
                    sans="SANS-6",
                    cwe="CWE-200",
                    endpoints=[endpoint],
                    poc=screenshot_file or "nmap ...",
                    consequence=http_log or "Service exposure",
                    likelihood="Low",
                    impact="Low"
                ))
        return findings
    except Exception as e:
        print(f"[Nmap Parse Error] {e}")
        return []

def parse_semgrep_json(output):
    try:
        data = json.loads(output)
        findings = []
        for result in data.get('results', []):
            endpoint = result.get('path', '')
            screenshot_file = None
            http_log = None
            try:
                screenshot_file = f"evidence_{uuid.uuid4().hex}.png"
                capture_screenshot(endpoint, screenshot_file)
                http_log = f"Semgrep log for {endpoint}" # Stub: real HTTP log capture needed
            except Exception as e:
                logging.error(f"[Evidence] Error capturing for {endpoint}: {e}")
            findings.append(Finding(
                name=result.get('check_id', 'Semgrep Finding'),
                severity=result.get('extra', {}).get('severity', 'Medium'),
                description=result.get('extra', {}).get('message', ''),
                evidence=result.get('path', ''),
                remediation=result.get('extra', {}).get('fix', ''),
                owasp=result.get('extra', {}).get('metadata', {}).get('owasp', ''),
                sans='',
                cwe=result.get('extra', {}).get('metadata', {}).get('cwe', ''),
                endpoints=[endpoint],
                poc=screenshot_file or '',
                consequence=http_log or '',
                likelihood='',
                impact=result.get('extra', {}).get('severity', '')
            ))
        return findings
    except Exception as e:
        print(f"[Semgrep Parse Error] {e}")
        return []

def run_wsl_scanner(command):
    print(f"Running WSL scanner: {' '.join(command)}")
    try:
        result = subprocess.run(['wsl'] + command, capture_output=True, text=True, timeout=300)
        return result.stdout
    except Exception as e:
        print(f"Error running WSL scanner: {e}")
        return ""

def run_scanner(name):
    print(f"Running scanner: {name}")
    cmd = SCANNERS.get(name)
    if not cmd:
        print(f"Scanner {name} not configured.")
        return ""
    if name.startswith("wsl_"):
        return run_wsl_scanner(cmd)
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        return result.stdout
    except Exception as e:
        print(f"Error running {name}: {e}")
        return ""

def parse_scanner_output(name, output):
    if name == "zap":
        return parse_zap_json(output)
    elif name == "nmap":
        return parse_nmap_xml(output)
    elif name == "semgrep":
        return parse_semgrep_json(output)
    # Add more as needed
    return []


# --- Information Gathering ---
def run_wappalyzer_cli(url):
    print(f"[InfoGather] Simulating Wappalyzer CLI for {url}")
    # Simulate detected tech stack
    return {"frameworks": ["Next.js", "Laravel"], "auth": "Passport"}

def run_zap_spider(url):
    print(f"[InfoGather] Simulating ZAP spider for {url}")
    # Simulate discovered endpoints
    return ["/api/user", "/api/admin", "/login", "/dashboard"]

# --- AI Planning & Threat Modeling ---
def ai_generate_test_plan(info):
    print("[AI] Generating test plan and checklist...")
    # Simulate dynamic checklist
    return [
        {"module": "Authentication", "tests": ["Password brute force", "JWT tampering", "Session fixation"]},
        {"module": "API", "tests": ["IDOR", "Privilege escalation", "Business logic abuse"]},
        {"module": "UI", "tests": ["XSS", "CSRF", "Broken access control"]}
    ]


# --- AI Engine (OpenAI Integration) ---
import openai
import os
from dotenv import load_dotenv
load_dotenv()
def ai_analyze(target_info):
    print("[AI] Querying OpenAI for business logic/abuse case testing...")
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("[AI] No OpenAI API key set. Falling back to simulated findings.")
        return []
    client = openai.OpenAI(api_key=api_key)
    prompt = f"Analyze the following target for business logic and privilege abuse vulnerabilities. Target info: {json.dumps(target_info)}. Return a JSON array of findings with fields: name, severity, description, evidence, remediation, owasp, sans, cwe, endpoints, poc, consequence, likelihood, impact."
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        content = response.choices[0].message.content
        findings_data = json.loads(content)
        findings = [Finding(**fd) for fd in findings_data]
        return findings
    except Exception as e:
        print(f"[AI Error] {e}")
        return []


# --- Remediation Guidance (AI) ---
def ai_remediation_snippet(finding):
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "// Add secure validation logic"
    client = openai.OpenAI(api_key=api_key)
    prompt = f"Suggest a code remediation snippet for the following finding: {finding.to_dict()}"
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"[AI Remediation Error] {e}")
        return "// Add secure validation logic"


# --- Fix Validation (Rerun Scanners) ---
def ai_validate_fix(finding):
    print(f"[FixValidation] Validating fix for: {finding.name}")
    # Rerun relevant scanner based on finding source (stub: rerun all for demo)
    for scanner in SCANNERS:
        output = run_scanner(scanner)
        parsed = parse_scanner_output(scanner, output)
        for f in parsed:
            if f.name == finding.name:
                print(f"[FixValidation] Finding still present: {f.name}")
                return False
    print(f"[FixValidation] Finding not detected.")
    return True


# --- Report Generation (PDF/Word) ---
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from docx import Document
def generate_report(report):
    print("Step 5: Generating Report (JSON, PDF, Word)")
    with open("pentest_report.json", "w") as f:
        f.write(report.to_json())
    print("Report saved to pentest_report.json")
    # PDF
    c = canvas.Canvas("pentest_report.pdf", pagesize=letter)
    c.drawString(100, 750, "Penetration Test Report")
    c.drawString(100, 735, f"Generated: {report.generated_at}")
    y = 700
    for finding in report.findings:
        c.drawString(100, y, f"{finding.name} - {finding.severity}")
        y -= 15
        c.drawString(120, y, finding.description[:80])
        y -= 30
        if y < 100:
            c.showPage()
            y = 750
    c.save()
    # Word
    doc = Document()
    doc.add_heading('Penetration Test Report', 0)
    doc.add_paragraph(f"Generated: {report.generated_at}")
    for finding in report.findings:
        doc.add_heading(finding.name, level=1)
        doc.add_paragraph(f"Severity: {finding.severity}")
        doc.add_paragraph(f"Description: {finding.description}")
        doc.add_paragraph(f"Remediation: {finding.remediation}")
    doc.save("pentest_report.docx")
    print("PDF and Word reports generated.")

# --- Dashboard Export (Stub) ---
def export_dashboard(report):
    print("[Dashboard] Exporting vulnerabilities and heatmap (real-time)")
    dashboard = {
        "generated_at": report.generated_at,
        "findings": [f.to_dict() for f in report.findings],
        "heatmap": {},
        "severity_count": {},
        "status": "completed",
        "certificate": report.certificate
    }
    # Calculate severity heatmap
    severity_levels = ["Critical", "High", "Medium", "Low", "Info"]
    for level in severity_levels:
        dashboard["severity_count"][level] = sum(1 for f in report.findings if f.severity == level)
    dashboard["heatmap"] = dashboard["severity_count"]
    # Export as JSON
    with open("dashboard_data.json", "w") as f:
        f.write(json.dumps(dashboard, indent=2))
    print("Dashboard data exported to dashboard_data.json")

# --- Report Generation ---
def generate_report(report):
    print("Step 5: Generating Report")
    with open("pentest_report.json", "w") as f:
        f.write(report.to_json())
    print("Report saved to pentest_report.json")


# --- Retest Module (Rerun Scanners) ---
def retest(report):
    print("Step 7: Retesting Module")
    for finding in report.findings:
        finding.status = "Fixed" if ai_validate_fix(finding) else "Not Fixed"
    print("Retest complete. Findings updated.")

# --- Certificate Generation ---
def generate_certificate(report):
    print("Step 8: Generating Certificate of Compliance")
    cert = {
        "title": "RMDT Web Application Security Certificate",
        "date": datetime.now().isoformat(),
        "summary": "This certifies the application has undergone automated and AI-assisted penetration testing as per OWASP, SANS, OSSTMM, and NIST methodologies.",
        "status": "Compliant"
    }
    report.certificate = cert
    with open("attestation_certificate.json", "w") as f:
        f.write(json.dumps(cert, indent=2))
    print("Certificate saved to attestation_certificate.json")

# --- Tool Health Check ---
def check_tool_health(tool_name):
    import shutil
    cmd = SCANNERS.get(tool_name)
    if not cmd:
        print(f"[HealthCheck] {tool_name} not configured.")
        return False
    exe = cmd[0]
    if shutil.which(exe):
        print(f"[HealthCheck] {tool_name} ({exe}) is available.")
        return True
    else:
        print(f"[HealthCheck] {tool_name} ({exe}) is NOT available.")
        return False

def check_all_tools_health():
    health = {}
    for tool in SCANNERS:
        health[tool] = check_tool_health(tool)
    with open("tool_health.json", "w") as f:
        f.write(json.dumps(health, indent=2))
    print("Tool health status exported to tool_health.json")
    return health

# --- Orchestration ---

def main():
    print("=== AI-Powered Penetration Testing Framework ===")
    report = Report()

    # Step 0: Tool Health Check
    print("Step 0: Tool Health Check")
    health = check_all_tools_health()
    unhealthy = [tool for tool, ok in health.items() if not ok]
    if unhealthy:
        print(f"[HealthCheck] The following tools are missing or not available: {unhealthy}")
    else:
        print("[HealthCheck] All tools are available.")

    # Step 1: Information Gathering
    print("Step 1: Information Gathering")
    url = "http://localhost:3000"
    wappalyzer_info = run_wappalyzer_cli(url)
    endpoints = run_zap_spider(url)
    target_info = {"url": url, "roles": ["admin", "user"], "tech": wappalyzer_info, "endpoints": endpoints}

    # Step 2: Planning & Threat Modeling (AI-Driven)
    print("Step 2: Planning & Threat Modeling")
    test_plan = ai_generate_test_plan(target_info)
    print(f"Test Plan: {json.dumps(test_plan, indent=2)}")

    # Step 3: Automated Scanning Layer
    print("Step 3: Automated Scanning Layer")
    for scanner in SCANNERS:
        output = run_scanner(scanner)
        findings = parse_scanner_output(scanner, output)
        for finding in findings:
            report.add_finding(finding)

    # Step 4: AI-Driven Manual Pentest
    print("Step 4: AI-Driven Manual Pentest")
    ai_findings = ai_analyze(target_info)
    for finding in ai_findings:
        # Add remediation code snippet
        finding.remediation += "\n" + ai_remediation_snippet(finding)
        report.add_finding(finding)

    # Step 5: Report Generation
    generate_report(report)
    export_dashboard(report)

    # Step 6: AI-Assisted Fixing
    print("Step 6: AI-Assisted Fixing")
    for finding in report.findings:
        valid = ai_validate_fix(finding)
        print(f"Fix for {finding.name}: {'Validated' if valid else 'Not Fixed'}")

    # Step 7: Retesting Module
    retest(report)

    # Step 8: Certificate of Compliance
    generate_certificate(report)

if __name__ == "__main__":
    main()
